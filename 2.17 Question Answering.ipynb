{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3a6027d4-b04c-4ad8-b2d4-92ced009fb85",
   "metadata": {},
   "source": [
    "## Credit\n",
    "\n",
    "Notes are taken from NLPlanet Practical NLP with Python course section 2.17 Question Answering \n",
    "* https://www.nlplanet.org/course-practical-nlp/02-practical-nlp-first-tasks/17-question-answering\n",
    "\n",
    "Authored by Fabio Chiusano\n",
    "* https://medium.com/@chiusanofabio94\n",
    "\n",
    "**All quotes '' are sourced from the NLPlanet course.**"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "2776c19e-af05-4399-99f7-e3a1d0a9cf5a",
   "metadata": {},
   "source": [
    "## Question Answering\n",
    "\n",
    "<u>Question Answering (QA) Models:</u>\n",
    "* Models capable of retrieving answers to a question from a given text.\n",
    "* Used for searching for specific information in large documents.\n",
    "* Answers can be directly extracted or generated by the model.\n",
    "\n",
    "<u>Question Answering Variants:</u>\n",
    "* <u>How answers are created:</u>\n",
    "    * Extractive QA:\n",
    "        * 'The model extracts the answer from a context and provides it directly to the user. It is usually solved with BERT-like models.'\n",
    "    * Generative QA:\n",
    "        * 'The model generates free text directly based on the context. It leverages Text Generation models.'\n",
    "* <u>Where answers are taken from:</u>\n",
    "    * Open QA:\n",
    "        * 'The answer is taken from a context.'\n",
    "    * Closed QA:\n",
    "        * 'No context is provided and the answer is completely generated by a model.'\n",
    "\n",
    "<u>QA Datasets (Academic Benchmarks for Extractive QA):</u>\n",
    "* SQuAD:\n",
    "    * (The Stanford Question Answering Dataset)\n",
    "    * 'A reading comprehension dataset, consisting of questions posed by crowd-workers on a set of Wikipedia articles, where the answer to every question is a segment of text from the corresponding reading passage.'\n",
    "    * 'Contains 100,000+ question-answer pairs on 500+ articles.'\n",
    "* SQuAD v2:\n",
    "    * A harder benchmark than SQuAD including unanswered questions.\n",
    "    * Combines the 100,000+ questions from SQuAD with 50,000+ unanswerable questions written by crowd-workers to appear similar to answerable questions."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d795520b-3c42-4c65-95a5-5d5a6392dc03",
   "metadata": {},
   "source": [
    "## QA in Python"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e769c79a-8d36-472c-9c9a-ec068068240b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install transformers library\n",
    "!pip install transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e1db6172-c7ce-45e7-9305-b7a75eae6a58",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports\n",
    "from transformers import pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4019ee5c-d421-470c-846a-920e222a4526",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No model was supplied, defaulted to distilbert-base-cased-distilled-squad and revision 626af31 (https://huggingface.co/distilbert-base-cased-distilled-squad).\n",
      "Using a pipeline without specifying a model name and revision in production is not recommended.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'score': 0.2543421983718872, 'start': 48, 'end': 90, 'answer': '0 degrees Celsius or 32 degrees Fahrenheit'}\n"
     ]
    }
   ],
   "source": [
    "# Question Answering Example\n",
    "\n",
    "# Download Model\n",
    "qa_model = pipeline(\"question-answering\")\n",
    "\n",
    "# Test Model\n",
    "question = \"How cold is snow?\"\n",
    "context = \"Snow begins to form at temperatures at or below 0 degrees Celsius or 32 degrees Fahrenheit.\"\n",
    "qa_response = qa_model(question=question, context=context)\n",
    "# Model returns a dictionary containing keys:\n",
    "    # score: the confidence of the model in extracting the answer from the context\n",
    "    # start: the index of the character in the context that corresponds to the start of the extracted answer.\n",
    "    # end: the index of the character in the context that corresponds to the end of the extracted answer.\n",
    "    # answer: the text extracted from the context, which should contain the answer.\n",
    "print(qa_response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "88fec99f-afd8-44bd-8d84-2b713d48eb2c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'score': 0.7124265432357788, 'start': 95, 'end': 111, 'answer': 'code readability'}\n"
     ]
    }
   ],
   "source": [
    "# More Complex Example\n",
    "\n",
    "context = \"Python is a high-level, general-purpose programming language. Its design \" \\\n",
    "\"philosophy emphasizes code readability with the use of significant indentation. \" \\\n",
    "\"Python is dynamically typed and garbage-collected. It supports multiple programming \" \\\n",
    "\"paradigms, including structured (particularly procedural), object-oriented and \" \\\n",
    "\"functional programming. It is often described as a \\\"batteries included\\\" language \" \\\n",
    "\"due to its comprehensive standard library.\"\n",
    "\n",
    "question = \"What does the Python design emphasize?\"\n",
    "\n",
    "qa_response = qa_model(question=question, context=context)\n",
    "print(qa_response)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d26d7330-9dda-43ad-84c8-708b84efe9d9",
   "metadata": {},
   "source": [
    "## Fast QA\n",
    "* Using a passage ranking model found on HuggingFace prior to the QA model can speed up the answer search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "7c2749b5-5910-472a-8397-565c50a2523c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rankings Look Like: \n",
      "[{'label': 'LABEL_0', 'score': 0.7719500660896301}, {'label': 'LABEL_0', 'score': 0.7145923376083374}, {'label': 'LABEL_0', 'score': 0.6634820103645325}]\n",
      "\n",
      "qa_response:\n",
      "{'score': 0.9973866939544678, 'start': 24, 'end': 32, 'answer': 'Einstein'}\n",
      "\n",
      "Confidence:\n",
      "0.9973866939544678\n",
      "\n",
      "Answer:\n",
      "Einstein\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Using a passage ranking model\n",
    "\n",
    "passage_pipe = pipeline(\"text-classification\", model=\"cross-encoder/ms-marco-TinyBERT-L-2\")\n",
    "\n",
    "passages = [\n",
    "    \"Wormholes, theorized by Einstein, are tunnels in spacetime that could potentially create shortcuts for long journeys across the universe.\",\n",
    "    \"The concept of wormholes remains a theoretical construct, suggesting the existence of shortcuts in spacetime to traverse vast cosmic distances.\",\n",
    "    \"Einstein's theory of general relativity introduced the idea of wormholes, hypothetical tunnels connecting distant points in space.\"\n",
    "]\n",
    "\n",
    "question = \"Who introduced the concept of wormholes?\"\n",
    "\n",
    "passages_with_question = [f\"{question} {passage}\" for passage in passages]\n",
    "\n",
    "# Embed\n",
    "rankings = passage_pipe(passages_with_question)\n",
    "print(f\"Rankings Look Like: \\n{rankings}\") \n",
    "\n",
    "# Get top-ranked passage\n",
    "temp_score = 0\n",
    "for i, rank in enumerate(rankings):\n",
    "    if rank['score'] > temp_score:\n",
    "        top_passage_index = i\n",
    "    temp_score = rank['score']\n",
    "top_passage = passages[top_passage_index]\n",
    "\n",
    "# Find answer\n",
    "qa_response = qa_model(question=question, context=top_passage)\n",
    "\n",
    "print(f\"\"\"\n",
    "qa_response:\n",
    "{qa_response}\n",
    "\n",
    "Confidence:\n",
    "{qa_response['score']}\n",
    "\n",
    "Answer:\n",
    "{qa_response['answer']}\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7f7acc5-21c5-4b47-ab79-d2dbc259f39a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
